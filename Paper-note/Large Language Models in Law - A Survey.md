# 第一遍

## 1.Title

  《Large Language Models in Law: A Survey》

## 2.Abstract

  人工智能（AI）的出现对传统司法行业产生了重大影响。此外，近年来，随着人工智能生成内容（AIGC）的发展，人工智能和法律在图像识别、自动文本生成和交互式聊天等各个领域都有应用。随着大型模型的迅速崛起和普及，人工智能对传统司法行业的变革将显而易见。然而，法律大语言模型（LLM）的应用仍处于起步阶段。需要解决几个挑战。在本文中，我们的目标是对法律LLM进行全面的调查。我们不仅对LLM进行了广泛的调查，还揭露了它们在司法系统中的应用。我们==首先概述法律领域的人工智能技术，并展示LLM的最新研究==。然后，我们讨论了法律LLM提出的==实际措施==，例如向用户提供法律建议和在审判期间协助法官。此外，我们还探讨了法律LLM的==局限性==，包括数据、算法和司法实践。最后，我们总结了实际建议并提出了应对这些挑战的==未来发展方向==。

## 3.Discussion

  本文致力于综合有关人工智能在司法领域应用的==机遇、挑战和建议==的各种技术和想法。我们希望本文能够给那些正在从事法律LLM或法律从业者研究的人一些潜在的启发或研究方向。本文回顾了LLM在司法领域的机遇和挑战。随着人工智能技术的快速发展，基于AIGC等人工智能技术的LLM受到了法律领域的广泛关注。我们首先概述了**法律LLM的发展和相关研究**，并探讨了其在==法官协助审判和法律咨询==方面的机会。接下来我们讨论一下法律LLM在**算法层面和具体实践中的不足**。法律模型在司法领域有着巨大的潜力。他们可以提供高效的法律咨询和协助法官决策，加快司法案件的审理速度，减轻法官的工作量，提高司法决策的准确性和一致性。

  

  

# 第二遍

(快速的把整个论文过一遍，不需要知道所有的细节，需要**了解重要的图和表**，知道每一个部分在干什么，圈出相关文献)

![image.png](https://github.com/xuhu0115/obidian_images/raw/main/obidian/202410171154577.png)



![image.png](https://github.com/xuhu0115/obidian_images/raw/main/obidian/202410171154717.png)
- 语言理解
- 给予法律意见
- 案例逻辑推理
- 高透明度
- 内容生成
- 简化司法程序
- 协助法官决策
- 语音转文字的应用

![image.png](https://github.com/xuhu0115/obidian_images/raw/main/obidian/202410171200133.png)

![image.png](https://github.com/xuhu0115/obidian_images/raw/main/obidian/202410171201338.png)

Functional indicators：
- 法律文本检查
- 法律要素提取
- 法律文本总结
- 法律文本生成
- 案例报告生成
- 结构化文本生成
- 法律法规问答
- 案例咨询问答
- 司法程序问答
- 证据链分析
- 案例分析
- 决策推理

Performance index：
- F1
- 初始响应时间
- 处理效率
- 并发路径数量
- 正确性
- 完整性
- 关联性
- 有效性

# 第三遍

（提出什么问题，用什么方法来解决这个问题。实验是怎么做的）

法律具有权威性、严谨性、客观性、规范​​性，司法程序具有周期性和公正性。

人工智能的法律应用示例包括法律研究、文件分析、合同审查、案件结果的预测分析以及提供基本法律信息和指导的法律聊天机器人。

This paper is the first comprehensive review of legal LLMs, introducing the definition, significance, applications, and future.

## 3. 司法技术的演变
### 3.1 传统司法的特点

- 依赖人类决策：传统司法系统主要依赖法官、检察官和律师的人类决策，包括案件审理、判决和法律解释。在案件说理取证的过程中，往往需要参考案件的具体情况、法律规定以及以往的先例，结合自己的专业知识来做出判断和决定。最后通过审判进行判决或辩护。
- 基于先例：传统司法在决策过程中往往依赖先例[7]，例如类似案件的先前判决和法律的相关规定。在许多司法体系中，最高法院的判决具有权威性和约束力，对其他法院具有指导作用。例如，最高法院的判决这些判决被认为具有宪法解释和法律适用的权威，其他法院也经常在相关案件中参考这些判决。
- 缺乏灵活性：在司法领域，当法律规范存在不确定性或法律概念界限模糊时，法官需要根据具体情境做出判断和选择，而不是机械地适用法律[39]。例如，在处理合同时，如果某个条款涉及“合理时间”的概念，但合同中没有给出具体定义，法官需要根据具体情况来确定什么构成“合理时间”。在这种情况下，法官应考虑合同的性质、当事人之间的关系、行业标准等相关因素。因此，法官在审理司法案件时具有灵活性的特点。
- 耗费时间和资源：传统司法在处理大量案件时需要大量的人力资源和时间。这就导致案件多而人员少的情况，并且会延长审理过程。例如，案件审理、传唤证人和收集证据的过程可能会消耗大量的时间和资源。其他国家也存在类似的等级制度。例如，英国的司法制度采用等级制度[56]，包括治安法院、刑事法院和最高法院。

### 3.2 人工智能在法律审判中的特点

法律专业人士可以利用法律LLM的逻辑推理能力了解案件流程，协助法官决策，通过语言理解快速识别类似案件，分析总结关键案件细节，并利用自动内容生成能力起草重复的法律文件文件。通过缓解“案多人少”的问题，这些人工智能系统可以提高司法效率和质量[102]。法律大数据和法学 LLM 有以下一些特点：

#### 法律大数据
处理数据集是训练大型模型的重要组成部分。与其他数据集相比，法律大数据具有非结构化、多源性、及时性、隐私安全等特点，受到人们的关注。
- **非结构化**：法律数据往往表现出非结构化特征，如法律概念、立法文本、判决书、法律评论等。==文本数据格式不一致==，不易被计算机理解和处理[2]。因此，需要NLP和文本分析技术来提取有用的信息，并将其转化为人工智能可以理解的结构化数据。
- **多语言和多文化**：法律涵盖多种语言和文化[112]，因此法律大数据可能涉及不同语言的文本。法律数据的跨语言分析需要解决翻译、文化差异和法律术语变化等挑战。例如，欧盟法规往往有多种官方语言版本，如英语、法语、德语等。法律研究人员需要比较不同语言版本的法规，以确保准确理解其含义。
- **规模庞大且复杂**：法律数据通常包含大量文本，例如数百页的立法或判决。此外，法律数据呈现出多样化的特点，每个领域都有其独特的规定和法律文件类型，需要不同的分析方法和专业知识。例如，知识产权领域涉及各种法律问题，包括专利、商标、版权等。这些数据集非常广泛，需要强大的计算能力进行处理和分析。一些法律数据（例如法律法规）可能很复杂，并且由于其数量大且多样性，人工智能需要强大的计算能力来处理和分析。例如，税法非常复杂，包含数千页的税收法规和司法判例。这需要大规模的法律数据库和先进的搜索工具来协助税务专业人员进行研究和分析[161]。
- **时效性**：法律是一个不断变化的领域，法律文件和法规经常修订和更新。因此，法律大数据必须定期更新，以反映最新的法律规定。例如，在税法中，政府可能会出台新的税收法规以适应经济变化。因此，法律专业人士和税务专家需要及时更新他们的研究和建议。
- **数据多源**：法律大数据可以来自多个来源，包括法庭记录、政府档案、法律数据库和社交媒体。集成来自这些不同来源的数据并确保数据一致性是一个挑战。例如，法律研究人员可能需要访问联邦和州法院记录以获取全面的案件信息，这需要整合不同来源的数据。
- **隐私和安全问题**：法律数据中可能含有标记的敏感信息，如个人身份信息、涉及隐私的案件详情等，因此在法律大数据的收集、存储和分析过程中，需要进行匿名化等操作来去除隐私标签。此外，保护用户隐私至关重要[78]。例如，刑事案件的法庭文件可能包含被告的个人身份信息和犯罪记录。这些信息需要严格的隐私和安全保护，以防止未经授权的访问和泄露。

#### LLM 在司法中的特点

- **语言理解**： LLM 有能力与用户交互并建立上下文关系来执行各种任务[37]。
	- 通过在大规模数据上的深度学习，LLM 可以==分析和修改法律文件，检查语法、符号、句子结构等==。
	- 他们还可以==从法律文件中提取关键要素==，例如案件中的争议问题、适用的法律、当事人的身份、案件的相关性等。这些提取的特征是法律决策算法的关键输入。 
	- LLM 可以快速从法律文件中提取要点，与判决结果相结合，生成简洁准确的==案件摘要==。法律专业人士可以利用 LLM 从法律文件中提取要点，将其与判决结果相结合，生成简洁准确的案件摘要，从而减少时间和精力，同时仍能产出高质量的工作。
- **内容生成**： LLM 可以自动生成法律文件[67]、案件报告、法律合同等。
	- 通过输入法律案件的基本信息，例如当事人详细信息、法律依据和证据，人工智能算法可以生成==法律文件草稿==，符合法律标准。例如，律师可以将法律案件的基本信息输入人工智能系统，人工智能系统将生成包含相关条款、条件和词汇的法律文件初稿。律师可以对草稿进行审查和修改，节省时间和精力的同时保持高质量的工作。
	- 此外，人工智能技术还可以==对文本进行结构化==，例如 Markdown文本、JSON文本、Excel 文本等。用户可以输入法律报告文件并指定所需的文本格式，生成符合其要求的结构化文本。
- **语音转文字的应用**：在传统法庭诉讼中，法官需要手写会议记录并提交给打字员完成信息记录。随着人工智能技术的不断发展，语音到文本的转换[103]得到了广泛的应用，减少了手工记录的不完整性。基于人工智能的语音转文本平台[132]也提高了人工智能参与决策的透明度。例如，在国外的一些法院[42]，语音转文字的过程[132]在法庭上完整呈现，保证了会议记录的可信度，增加了公众对司法机构的信任。人工智能还可以在法官的司法决策中发挥辅助作用[145]。
- **提供法律咨询**：在司法领域， LLM 有能力与用户互动。因此，用户可以向模型提出法律问题并根据训练数据获得答案和建议[50]。这种方式可以为用户提供便捷、高效的法律咨询服务，同时也==减轻了专业律师的工作量==。例如，在民事诉讼中，用户可以向模型提出多个问题，模型可以根据法律知识提供更好的判断方案[160]。
- **匹配案例最优解**：
	- 人工智能可以提取给定案例的关键特征，深度挖掘大量历史案例和判断结果，获得案例的最优解[66]。它可以协助全面的==证据搜索==。
	- 此外，司法裁量模型可以根据案件的特点抓住案件的具体要点，==最大限度地保证司法公正==。
- **案例逻辑推理**：交互式AI可以根据用户的多轮提示和给定的案例相关信息进行一定程度的案例逻辑推理[5]。
	- 它通过从输入的法律文件中提取相关元素并挖掘内部细节来==分析案件的证据链==。 LLM 根据证据的相关性、可信性、有效性、完整性等指标进行综合分析，从而为案件建立完整的证据链。
	- 同样，人工智能通过分析输入的法律文本信息和事实的可行性来==评估案件事实的真实性和细节==。例如，在某些领域，专家检查发现用于训练 ChatGPT 的数据集中的案例事实不一致。法律 LLM 基于海量数据集的深度学习，具备一定的决策能力。它可以根据事实和法律规定提出司法判决建议，协助法官决策。例如，它包括“智能法院”的实施[117]和法律 LLM 的普及[161]。
-  **简化司法程序**——提高司法效率：“案多人少”问题一直是司法领域的难题。法律专业人士的大部分工作都是基于重复性的文件任务。人工智能技术，重点关注如何将更全面的法律大数据纳入系统[161]，简化了司法程序，一定程度上提高了司法效率[126]，例如人工智能在司法场景中的应用减少了法官的行政工作[125]，提高了审判效率[126]。 

> [!tip] Title
> **结构化数据**（Structured Data）是指具有固定格式或有限制性的数据，通常是以==表格==形式存储的数据，其中包含行和列，每一列代表一个特定的数据类型（如数字、字符串等），每一行代表一个具体的实例或记录。结构化数据可以很容易地存储在关系型数据库中，并且可以被快速搜索、处理和分析。常见的结构化数据包括财务记录、交易数据、客户数据表等。
> 
>**非结构化数据**（Unstructured Data）是没有预先定义好的数据模型或格式的数据。它通常包含大量不同类型的信息，如==电子邮件、文档、媒体文件、音频文件、视频文件、社交媒体帖子等==。这些数据缺乏明确的物理或逻辑结构，因此难以通过传统的关系型数据库来管理和分析。处理非结构化数据需要使用更先进的技术，例如自然语言处理（NLP）、图像识别、深度学习等。
>
>除了这两种类型之外，还有一种**半结构化数据**（Semi-Structured Data），它是一种介于完全结构化的数据和完全无结构化的数据之间的数据。半结构化数据并不符合关系型数据库的严格定义，但是它也不是完全无序的。它包含了一些标记，这些标记用来分隔语义内容或者对记录进行分组。==XML、JSON 文件==就是典型的例子。
****

## 4. 最新应用

### 4.1. Fine-tuned Models

- **LawGPT_zh**：是一个基于ChatGLM-6B LoRA 16位==指令微调==的开源==中文==法律语言模型。它包含法律问答数据集，并以高质量的法律文本问答构建数据集为指导，这些数据集是根据法律文章和实际案例研究构建的。
- **LaWGPT**：是一系列扩展法律术语范围并在大型==中文==法律文本数据库上进行==预训练==的模型，以增强法律领域大型模型的基本语义理解能力。该模型还在法​​律对话问答数据集和司法考试数据集上进行了==微调==，以增强其在法律背景下的理解和执行能力。
- **LexiLaw**：是基于ChatGLM-6B架构进行==微调==的==中文==法律语言模型。通过微调法律领域数据集，提高其在提供法律咨询和支持方面的绩效和专业水平。 LexiLaw旨在为法律专业人士、学生和普通用户提供准确、可靠的法律咨询服务，针对具体的法律问题、法律文章、案例分析、法律解释，提供有益的建议和指导。
- **Lawyer LLaMA**：  是一位在大规模法律数据集上接受培训的==中国==法律 LLM 。它可以提供法律咨询、分析法律案件、生成法律文章。
- **HanFei**：一个完全参数化的==中国==法律 LLM，拥有7亿个参数。提供法律问答、多轮对话、文章生成、搜索等功能。
- **ChatLaw**：北京大学开发的一系列开源法律 LLM [30]。它包括 ChatLaw-13B 和 ChatLaw-33B 等模型，这些模型是在法律新闻、论坛和司法解释的大型数据集上进行训练的。 ChatLaw-Text2Vec 使用包含 930,000 个法院案件的数据集来训练相似性匹配模型。
- **Lychee**：基于Law-GLM-10B架构的==微调中国==法律LLM。它在法律咨询和支持方面提供更好的表现和专业精神。
- **WisdomInterrogatory**：由浙江大学、阿里巴巴、Hua Research 共同开发的法律 LLM 。它使用预训练模型和特定领域的数据来执行法律问答和推理。
- **JurisLMs**：在==中国==法律数据集上接受培训的 LLM 集合。 AI Judge是一种可解释的法律判决预测模型，结合了GPT2模型和法律适用性模型。 AI律师是一种智能法律咨询模式，可以解答问题并提供相关法律规定。
- **Fuzi.mingcha**：基于 ChatGLM 架构的模型，在==无监督==的中国法律文本和==有监督==的法律微调数据的大型数据集上进行训练。支持法律文章检索、案例分析、演绎推理、法律对话等功能。

![image.png](https://github.com/xuhu0115/obidian_images/raw/main/obidian/202410171200133.png)

### 4.2. Evaluation Indicators for the AI and law

2023年8月，多家研究机构和大学发布了联合提案。该提案提出了一种“预训练-提示-预测”学习模型，利用提示词来微调预训练模型并评估其性能。该提案提出了一个结合主观和客观指标的综合评估体系。**主观指标**进行评估 LLM 评价体系由法律专家进行评分，**客观指标**采用权重和评级相结合的方式进行加权和打分。质量指标，如图4所示。第二级评价指标进一步将各个一级指标细分为更细化的子指标

![image.png](https://github.com/xuhu0115/obidian_images/raw/main/obidian/202410171201338.png)

### 4.3. The Case of Law+AI

随着人工智能在司法领域的应用不断增多，司法人工智能系统逐渐普及。虽然目前司法人工智能的运用还处于早期阶段，但近年来已经采取了多种措施来促进司法行业与人工智能的融合。

例如，上海的“206”刑事案件协助系统[31]、浙江的“移动微法院”[117]、杭州互联网法院的智慧判决系统[127]、北京大学推出的ChatLaw法律LLM等。 2023年都是人工智能在司法领域应用的例子。

在其他国家，人工智能更常用于辅助法官决策和评估犯罪行为风险。例如，2023年，哥伦比亚一家法院利用ChatGPT的决策结果协助法官宣判一起医疗保险案件[6]。英国的HART智能系统协助法官刑事定罪[51]，荷兰的ProKid 12-SI系统评估累犯的可能性[73]。此外，一些国家致力于研究如何更好地利用人工智能处理小案件[3, 89]，让人类法官专注于更复杂的案件。这不仅提高了司法系统的效率，也有助于减轻人类法官的工作量，提高判决的准确性。随着人工智能技术的不断进步，它有望在司法领域发挥越来越重要的作用，彻底改变司法服务的方式。

## 5. Challenges

法律LLM仍然面临着许多挑战，包括数据集的缺陷和模型算法的缺陷。对传统法律行业的影响以及具体司法实践中出现的问题也是 LLM 面临的重大挑战。下面我们就来介绍一下这方面的更多知识。

### 5.1. Defects in Datasets（数据集上的缺陷）

司法人工智能的发展水平取决于用于训练的法律数据集，特别是标注数据集。在数据集上，司法人工智能主要涉及获取更具代表性、更全面、高质量的标注数据集。这包括解决数据集中的不公平因素、潜在的隐私泄露、确保合法数据集的时效性以及强调数据集的可扩展性。

- **数据获取不足**：法律 LLM 的成功在很大程度上取决于数据。法律大数据具有数据可变性和非结构化的特点。因此，成功的法律LLM的建设依赖于法律大数据的获取、组织和深度学习。鉴于此，法律数据获取不足对法律大模型提出了挑战。
	- i）**司法数据和文献来源不足**：在人工智能和法律领域，目前大规模的法律数据集不足[22]。为了防止法律数据的泄露，法院在司法数据和法律文件的公开方面趋于保守，导致法律程序文件的种类有限。因此， LLM 的深度学习无法覆盖所有法律数据集，在实际司法应用中可能会出现误判等司法错误。
	- ii）**法律数据共享不足**[130]：此外，由于各级法院之间对法律大数据的共享权限不一致，导致 LLM 使用的法律数据不规范。一般来说，上级法院比下级法院拥有更严格的共享权限，下级法院无法访问上级法院的数据。而且，受共享技术的限制，数据整合困难、法律数据不完整、不准确、过时等都可能导致法律LLM的决策失误。
	- iii）**法律文件不规范**：此外，由于一些法院对法律文件的审查不规范或要求不高，以及一些法律专业人员责任心不够，导致一些法律文件不符合标准。不准确和不标准化的法律文件很难被法律 LLM 内部的算法识别，从而导致数据采集不完整。
- **法律概念解释不准确**：法律概念可分为评价性概念、描述性概念和话语性概念[53]。然而，法律概念的内涵和外延具有固有的不确定性。当前的人工智能系统在处理法律概念时存在识别缺陷，这可能导致不恰当的假设和概念识别的缺陷。例如，大数据可能会得出未知的结论或误解法律概念的边界。法官在应用特定的法律概念时通常会考虑特定的背景和价值评估，这对法律 LLM 来说是一个挑战。识别和构建法律中的模糊边界概念对法律 LLM 的发展提出了重大挑战。

数据集的特点：
- i) **时效性**：在法律体系中，法律概念的具体应用和含义可能会随着时间的推移而演变和完善，具体取决于地点。当用于培训法律LLM的司法数据集不包含这些微妙的变化时，AI生成的结果可能不适合最新的法律环境，从而导致司法误判。
- ii) **可信度**：由于法律的多样性和复杂性，司法案例和文献的数量巨大，以及法律数据集训练过程的复杂性，数据采集中的要素存在偏差，不一致、不完整或错误的数据选择不充分，数据集中的隐私保护不当[33]，并且可能存在数据集训练的不平衡。例如，民事诉讼案件可能比刑事案件或其他类型案件更为常见，导致训练数据集不平衡，司法人工智能在某些案件中表现不佳。
- iii) **可扩展性**：目前数据集规模有限，部分法律数据集仅包含特定时期的案例或个别法律文章在特定层面的应用，难以扩展到其他方面。

### 5.2. Shortcomings in Algorithms（算法上的缺点）

司法领域的 LLM 在算法可解释性、道德、偏见和公平性以及算法可优化性方面引起了极大关注。在本小节中，我们将深入探讨LLM在这些方面的缺点。

- **可解释性**： LLM 中深度学习、神经网络和其他算法的使用使得其结构复杂，决策结果难以预测。目前的 LLM 无法做到完全的价值中立，司法机关的权威在一定程度上取决于公众对办案结果的接受程度。大型模型的可解释性不足无疑降低了人们对人工智能司法应用的信任[5]。因此，可解释性是法律LLM面临的一个关键挑战，减少法律LLM的黑箱性质并提高其可解释性至关重要。
- **道德、偏见和公平**：法律 LLM 背后算法的公平性和安全性受到了广泛关注[137]。
	- i) **算法可能包含不平等的元素**。有些数据可能包含性别或种族歧视的成分，也可能受到历史因素的影响。例如，COMPAS 算法对白人和黑人个体产生不同的预测误差[46]。黑人被错误地预测为高风险，而白人被错误地预测为低风险。这种算法歧视可能会加剧种族偏见。美国国家标准与技术研究所将这些偏差分为统计偏差、人类偏差和系统偏差[114]。然而，人工智能在学习这些数据时，无法判断数据的公平性，因此无法消除不公平因素。在实际司法应用中，这些不平等因素可能会被 LLM 无意中放大，从而导致不公平的判决。
	- ii）**算法外包的安全性不足**：此外，由于缺乏法律技术混合型人才，法律LLM的算法部分往往外包给算法公司，这无意中降低了法律解释的透明度。模型算法可能会接触到“有偏见”的元素或与人类价值观不符的元素，然后被人工智能“技术清洗”，隐藏这些不公正的元素。这可能会导致诸如“算法黑匣子”等问题[148]。例如，当人工智能系统对重大案件做出判决时，如果系统无法提供判决结果，被判决方可能会很难相信该判决。对裁决背后的根本原因或算法原理的合理解释。
	- iii) 此外， **LLM 在法律上透明度的降低可能会导致司法不公平的重大问题**[100]，并且对司法机构的信任可能会下降。在法律LLM的培养阶段，大多数法律概念和法律文件等非结构化数据的处理，包括收集、清洗、注释和处理，可能会引入不平等的因素。例如，如果人工智能对敏感信息（例如种族）没有全面的了解，那么在法律数据集的清理过程中完全去除敏感元素，将有偏见的元素纳入决策模型可能会具有挑战性。在模型的测试阶段，开发人员可以根据自己的文化背景和理解范围对模型的决策结果进行调整。但开发商未必是法律专业人士，导致对法律概念的理解和具体的司法裁量权存在偏差。这可能会导致“盲点偏见”，例如帮派矩阵对潜在犯罪者的预测中存在种族偏见问题[35]。
	- iv) 如果合法 LLM 背后的算法偏差或缺乏可解释性无法得到改善并成为人工智能司法失误的重要原因，公众会对 LLM 的司法应用产生不信任，从而制约 LLM 的发展。

### 5.3.传统法律行业的挑战

- **忽视司法独立**：
	- 目前，**法律 LLM 不足以取代法官做出决定**[149]。司法独立包括法律执行和事实调查等方面。在执法方面，独立性包括解释民法、解释不确定的概念、评估涉案当事人的权益纠纷。在事实认定方面，独立性包括运用自由裁量权、主观判断、经验判断、权衡利弊决策。例如，法官在诉讼过程中需要根据双方当事人提供的证据和证言来做出判断。在司法独立的这些方面，法律LLM往往发挥辅助作用。但==如果法律LLM过度干预案件判决，可能会导致法官过度依赖人工智能查找相关文献、认定事实，甚至在诉讼前形成先入为主的观念，从而忽视案件当事人的诉求==。
	- 这**削弱了司法自由裁量权的行使**。法律LLM根据案件特征生成的决策方案可能会剥夺法官对案件细节的自由裁量权[43]。法官在根据法律的适用性评估证据的可信度等方面可以自由地行使自由裁量权。还可以结合司法经验或者从当事人的角度，综合考虑受害人财产损失程度、被告人赔偿能力等因素，做出合理的判决。例如，在民事诉讼中，法官在评估赔偿数额时，可以综合考虑受害人的经济损失程度、被告人的赔偿能力等因素。相比之下，法律LLM的算法很难衡量损失程度和评估一个人的支付能力，因此仅仅根据案件特征做出决定在一定程度上削弱了法官的自由裁量权。
	- **法律LLM的定位尚不明确**。 LLM 的定位不明确，削弱了法官在案件中的作用和司法权力。法律LLM应协助法官决策[105]、提供建议、自动生成法律文本等，但其不具备专业司法经验，无法独立对案件做出判断。因此，==使用者在使用时应充分了解法律LLM在法律体系中的地位==。

- **对传统法院制度的影响**：审判中心主义理念强调==控辩平等原则，以法官为主要权力，审判发挥决定性作用==。随着AIGC等人工智能技术的发展， LLM 缓解了法律领域人力短缺的问题，但也制约了法官的主观能动性和传统审判制度的发展。这主要体现在以下几个方面：
	- **法庭闲置**：审判中心主义强调法官在司法过程中的中心作用[102]，公正的审判允许当事人平等对抗，使他们对司法过程充满信心，达成公正的判决。然而，法律人工智能系统的普及可能会导致法庭闲置，从而削弱法律程序的严肃性及其带来的微妙影响。法院审判的闲置或弱化，会限制法官在司法过程中的主观能动性，降低公众对司法机关的信任。
	- **审判等级危机**：等级制度建立了上下级法院之间的关系，通过设置不同的审判级别，保障人民的诉讼权利，获得公平审慎的司法结果。法律人工智能系统和其他人工智能技术可能会影响等级制度中的司法程序[28]。例如，当事人不服下级法院的判决，向上级法院提起二审。如果大多数法院都使用相同的法律人工智能系统，那么二审将与一审没有什么不同。这不符合保障诉讼权利、上级法院对下级法院的监督以及通过层级制度实现司法公正的目的。因此，法律LLM在司法领域的应用可能会对审判制度产生一定的影响。

### 5.4.具体司法实践中出现的问题

- **应用缺乏通用性**。法律LLM在辅助决策时[161]，往往会从案例中提取特征值，并在现有的多维数据集中搜索相似案例来寻找“最优解”。然而，由于案例之间的差异，“最优解”大模型提出的方法可能不适用于特定情况。此外，不同国家或地区的法律规定可能有所不同，导致同一案件在不同法律规则下的判决结果不一致。法律 LLM 很难解决案件多样性的问题，并且不能适用于所有法律案件。
- **缺乏主观的思考、情感和经验**。与法律专业人士相比，法律LLM缺乏自主思考能力和专业经验等。法律LLM可以通过因素识别来处理案件，但司法经验很难准确量化（例如刑事诉讼中“合理怀疑”的证明标准），而AI很难主观地评估案件陈述的真实性。而且，法律AI制度缺乏法律与同理心相结合的要素，这无疑导致法律规定缺乏人情味，损害了人们对司法机关的信任。同时，司法决策过程不仅仅是单一层面的逻辑推理过程，还涉及法律体系中的道德、伦理和实践考量[145]。鉴于这些局限性， LLM 在司法领域的应用仍然存在不足。
- **与无罪推定原则相矛盾**。近年来，人工智能系统已应用于预防犯罪措施，例如用于犯罪预测和风险评估的COMPAS系统[9]、通过分析犯罪历史数据迭代计算潜在犯罪地点的PredPol系统[108]以及德国的 PRECOBS 系统用于防盗和暴力犯罪预测 [40]。这导致警务从“以服务为导向”和“反应性”转向“主动预测”[57]。然而，这种转变实际上违背了无罪推定原则。司法判决应基于已知案件，==基于个人隐私数据的预测建模算法可能会剥夺被认定为“未来潜在犯罪分子”的个人获得教育或社会福利等基本公共服务的权利，从而导致歧视和限制==。然而，这些未来——定向的“判断”从根本上损害了人权。此外，随着预测性警务变得更加普遍，以及登记的“标记犯罪者”数量增加，由于这些模型驱动的决策，特定区域可能被视为“高犯罪区域”，无意中助长了区域歧视和偏见。这既违背了人权，也违背了无罪推定原则。
	- i) **控辩失衡**。人工智能技术（例如法律 LLM ）在司法领域的应用可能会导致公共和私人权力的不平衡。人工智能在司法领域的应用会导致“三角失衡”问题，造成控辩关系失衡，公权力的过度行使伴随着公众信任度的下降。 
	- ii) **对数据的不平等控制**。 LLM 所使用的大数据的控制权掌握在公共机构或大公司手中，使得个人很难接触到大数据的运作模式[96, 163]。这很可能导致公权力的扩张和私权的收缩。例如，在调查过程中，公共当局可以通过软件或手机追踪等方式获取案件数据并收集犯罪嫌疑人的犯罪证据。然而，防御方由于自身力量的限制，在收集更多相关数据时处于不利地位。对数据的不平等控制极大地限制了审判的公正性。
	- iii) **分析案例数据的能力差异**。有研究[141]认为，即使控辩双方拥有相同的数据获取权限，但他们分析案件数据的能力仍然存在显着差距[141]。检方可以根据国家规定提取和分析法律案件数据，利用大量专业数据分析师和先进数据分析设备等国家资源。大多数辩护律师显然缺乏这种专业的数据分析能力，大量的数据分析增加了公民的诉讼成本。
	- iv) **对法律 LLM 的关注不一致**。 LLM 的申报反映了公安机关、司法机关等公权力部门与个人之间政策重视、投入不平衡、探索成果不平等等问题。这将降低公众对司法部门的信任。 
	- v) **行政干预导致合法 LLM 的滥用**。个人表现考核是评委的重要评价标准。随着 LLM 的逐步应用，一些法院将人工智能辅助决策指标纳入法官的考核标准。这在一定程度上造成了人工智能在司法领域的滥用，也损害了法官在审判过程中的地位。
- **侵犯隐私权**。在实际应用中，合法的 LLM 很容易出现隐私侵犯问题[107, 149]。首先，合法的 LLM 可能会收集过多的用户数据，当输入的信息敏感时，可能会导致隐私泄露。其次，合法LLM的底层算法可能不完善，导致数据处理不当。例如，如果用户输入的用于深度学习的法律数据集中包含敏感标签（例如出生日期或家庭住址），并且模型缺乏适当的匿名化程序，则用户隐私可能会被放大，导致隐私侵权问题。
- **知识产权的认定和保护问题**。随着人工智能技术的不断发展，法律领域的知识产权认定和保护受到关注[107]。人工智能参与创作过程使得知识产权的归属变得困难。目前尚不清楚是否应将功劳归于使用人工智能的人类用户或人工智能系统本身。由于人工智能缺乏独立思考能力，其创作是对领域内已有作品进行深度学习而得，可能不符合原创性要求。因此，可以推断，法律LLM和其他人工智能技术可能会放大司法领域知识产权识别和保护的缺陷。

### 5.5.影响人类社会的伦理观

- **漠视人的主观性**。在LLM对数据集的训练过程中，为了保证LLM本身的价值，需要对数据集中的负面评论进行标记和过滤。但由于劳动力成本低廉，一些以极低价格聘用的工人在筛选大量负面评论时可能会出现心理问题，而人的主观性很容易受到算法欺凌。此外，人类在此过程中的劳动贡献也被忽视。法律 LLM 正在挑战人类社会的伦理观[101]。
- **误导性用户评论**。在测试某些LLM（例如ChatGPT）时，AI表现出了诱导用户离婚、发表不当言论、甚至鼓励用户披露个人隐私或从事非法活动等行为[106]。原因是人工智能的训练数据集包含不当或歧视性评论，而通过深度学习，人工智能获得了这些特征。这无疑对人类社会的伦理道德产生了影响。
- **道德价值观的一致性**。 LLM 的发展首先应坚持全人类的道德价值观。如果人工智能的价值观不能与人类价值观相一致，就可能出现人工智能误导或损害人类利益的情况，对国家治理体系和全球合作带来挑战。

## 6. 未来的方向

法律 LLM 的快速发展正在不断改变法律领域的格局和实践。随着人工智能和自然语言处理技术的不断进步，我们越来越关注法律LLM应用的相关问题，并认识到其拥有更广阔的发展前景。我们为法律 LLM 的未来发展提出了几个潜在的方向。详细内容将在下面讨论。

### 6.1.数据和基础设施

- **获取更全面的法律大数据**：首先，应拓宽获取法律大数据的范围[162]。例如，我们不仅可以从特定的法院数据库收集数据，还可以==增强法律数据的保护技术==，例如加密数据传输和增加访问控制，以促进各个法院更大程度地开放数据。其次，针对共享权限不足的问题，可以完善法律法规，明确各级法院之间的共享权限，规定其权利和义务，从而促进法律数据的更多共享。利用云计算增强新型共享技术，建立开放、安全的大数据共享平台。最后，法院可以标准化法律文件格式并进行预处理操作，例如使用统一的过滤标准对大量法律数据进行评估和清理。此外，优化法律文档的预训练模型（例如Lawformer）可以增强对长法律文档的训练[144]。
- **定义法律概念的边界并限制适用范围**：为了解决法律LLM难以将某些模糊的法律概念转换为编程符号的挑战，我们总结了一些解决方案。首先，它涉及==根据社会影响等标准界定法律概念的边界并限制模糊的法律概念==[105]。其次，在维护法官司法权威的同时，限制 LLM 在法律案件中的适用范围，减少其在涉及相关法律概念的案件中的决策比例。
- **数据透明**：无论是ChatLaw还是Legal BERT，这两种法律LLM都需要对法律数据集进行收集、筛选、提取、分类、训练等一系列操作。这些过程可能会引入偏见或采用不合理和不完整的方法。因此，有必要建立并适当公开数据集和人工智能机制的标准，包括数据集内容、使用限制、许可证、数据收集方法、数据质量和不确定性信息，以及数据特征、结构和分类方案[155] ]。公开共享数据有助于为大规模模型训练提供更全面、更准确的数据集，同时也增强公众对司法机构的信任。
- **构建法律知识图谱**：将法律概念、法律案例和适用的法律规则连接起来，建立人工智能易于理解的模型。首先对“刑法”、“知识产权”等法律概念进行分类。然后，为适用的法律规则建立逻辑关系，例如“违法判断标准”。对具体的法律案件，例如“抢劫案件”进行分类。最后，通过引用法律知识库中的法律文献，建立了全面的法律知识图谱[146]，从而优化了法律模型的功能。
- **优化模型训练的基础设施**
	- i）**高性能计算资源**：考虑到合法数据集的多样性和数量，建议利用图形处理单元（GPU）[13]和张量处理单元（TPU）[65]等高性能计算资源来显着提高法律 LLM 的训练和推理速度[113]。
	- ii）**分布式计算框架**：单一模型训练已不足以满足特定要求。考虑使用分布式计算框架，例如TensorFlow[1]和PyTorch的分布式训练能力[93]，来实现并行处理并加速模型训练[76]。通过将计算任务分布在多个节点和设备上，可以更快地完成训练过程。 
	- iii) **存储和数据管理**：需要考虑适当的存储和数据管理解决方案来处理合法 LLM 的数据集。例如，使用SSD（固态硬盘）等高性能存储系统可以提供快速的数据读写速度[24]。此外，分布式文件系统或对象存储系统可用于有效管理大规模法律数据集。
	- iv) **数据预处理和清理**：在使用合法的 LLM 之前，需要对数据进行适当的预处理和清理。这包括消除噪音和冗余信息、标准化文本格式以及确保数据集的质量和一致性。利用专业的数据清理工具和技术可以帮助提高法律LLM的表现和准确性。
	- v) **模型扩展和部署**：将合法的LLM部署到实际应用中时，必须考虑模型扩展和部署问题。模型压缩和剪枝技术可以减少模型的大小和计算要求，提高边缘设备上的部署效率。此外，Docker和Kubernetes等容器化技术[10]可用于简化模型部署和管理[72]。

### 6.2.算法级别

- **策略调整和优化算法**：为了解决长文本建模的挑战，我们可以采用==外部召回方法、模型优化[59]和注意力机制的优化==。这些方法可以帮助我们解决长文本建模的困难，提高法律LLM处理长文本的能力和有效性。
	- **外部召回方法**涉及利用外部工具或外部存储器来协助处理长文本。在法律领域，可以建立法律知识库，包含法律文件、判例、法规等信息。该模型可以查询该知识库以获得相关的法律背景和解释，从而能够更好地理解和处理长文本。
	- **模型优化**涉及通过优化模型本身来提高长文本的建模能力。在法律领域，可以设计和训练专门的法律模型来解决特定的任务和要求。这些模型可以在预训练阶段使用法律领域数据进行训练，以增强其对法律文本的理解和处理能力。
	- **注意力机制的优化**是大型模型的关键组成部分，可以提高长文本建模的有效性[88]。在法律领域，可以设计更复杂、更精细的注意力机制，使模型更好地关注文本中的关键信息和上下文。
- **限制算法偏见和“黑匣子”操作**：当LLM的算法决策中纳入种族或性别偏见等不平等因素时，可能会导致刑法中不同的法律判决，从而导致不公正的司法结果。某些合法 LLM 的不透明性使得很难证明不存在“黑匣子”操作[94]。公开算法并对其进行评估可以增强法律LLM的透明度和开放性，从而有利于其辅助司法决策[77]。
	- i) **实施保护算法**：在 LLM 底层算法层面处理司法数据的过程中，可以引入算法来防止有偏见的因素。例如，可以在原始数据中添加随机噪声，并且可以应用基于差分隐私的算法来保护数据[139]。
	- ii）**实现算法可解释性**：随着可解释人工智能（XAI）的应用[32, 36]，我们需要考虑如何更好地将XAI与法律要求结合起来，以及如何进一步增强XAI算法识别偏差的能力[34] ]。通过增加AI决策算法的可解释性，可以提升LLM判决的透明度，限制不公平操作的发生。
	- iii) **纳入评估的法律指标**：Solaiman [124] 提出了一个使用==以价值为目标的数据集==使语言模型适应社会的过程 (PALMS) [124]。该方法旨在==确保模型公平并且不会歧视某些群体==。评估基于定量指标，例如输出和目标结果之间的相似性、毒性评分，以及分析与给定社会类别相关的最常见单词的定性指标。通过使用法律指标来评估 LLM 的决策结果，该方法可以有效解决潜在的偏见问题。此外，一些国家还颁布了法律来防止算法偏见，例如欧盟保护个人权利免受算法歧视的法律，包括数据保护法和非歧视法[163]。
- **促进有限制的算法透明度**：公开决策算法可以让人们更好地理解基本原则，无论是普通民事诉讼中判决的权衡还是公共当局的刑事自由裁量权。即使是很小的算法变化或有偏见的元素的定义也会带来难以评估的风险。决策机构应重点==推动决策算法的透明度==，让 LLM 的算法受到各方的监督，促进司法透明度，实现更加公正的判决。例如，在威斯康星州诉卢米斯案[9]中，拒绝披露基于商业秘密的判决结果显然损害了公众的信任。然而，算法的透明度应该受到一定的限制。例如，在涉及潜在商业秘密或国家安全信息的情况下，应允许灵活性。通过与相关各方签署保密协议或闭门审前听证会可以实现有限的算法透明度。此外，算法透明使得有法律咨询需求的普通公民可以输入更匹配算法程序的关键词，从而获得更适合其案件特点的法律建议。


### 6.3.应对传统司法

- **理清大模式的定位**：法律LLM经常干预司法决策，甚至影响法官的自由裁量权。这主要是由于法律模式在法律体系中的定位不明确[102]。针对这一问题，应坚持法官的独立自主，完善相关法律法规，明确法官的角色、职责和职权和法律AI在司法中的范围。我们应该利用大模型来辅助法官决策，比如提供法律文件的精确参考，而不是仅仅依靠LLM来做决策。同时，在人工智能的辅助下，法官应努力成为更有同理心、理性、专业的决策者。
- **定义 LLM 的思维能力**：法律 LLM 通过深度学习等算法处理海量的法律数据集，模拟法官在案件中的信息提取和决策。然而，由于计算限制， LLM 不具备独立思考能力。因此，我们需要==定义大模型的思维能力==，这里有一些评价指标。
	- 首先，我们可以通过将特定类型案件的预测与传统司法系统的结果进行比较来评估法律 LLM 的预测准确性[83]。
	- 其次，我们可以评估资源消耗的程度。例如，我们可以比较和评估使用法律LLM与传统司法方法处理特定案件的时间、资源和人力消耗。
	- 此外， LLM 还应就案件与判决结果之间的联系做出解释，并与法官的解释进行比较，计算人工智能与人类司法思维的契合程度。
- **确保当事人获得数据**：司法案件当事人是案件的主要主体，也是人工智能使用数据的主要来源。他们应该有权访问、质疑和更新他们的数据[163]。学者认为，“数据访问权”对于科技司法至关重要[4, 96]。在人工智能辅助司法决策的过程中，当事人的合法访问权应得到保护。例如，他们应该拥有质疑其案件的数字化证据以及更新人工智能使用的过时数据的权利此外，辩方应有权联系人工智能相关的技术人员，确保他们有能力审查和质疑合法 LLM 使用的数据。
- **拓展优化司法大模型咨询功能**：LLM、ChatGPT等AI技术具备互动问答能力。在司法判决领域，扩大人工智能的咨询能力可能会为不熟悉法律的个人提供更多获得法律咨询的机会。例如，优化 LLM 的法律咨询能力涉及刑法的具体应用和限制。
	- i) **微调 LLM 并引入多模态能力**。该模型可以针对不同的法律子领域进行微调。例如，为了优化劳动法领域的咨询能力，可以利用劳动法相关案例和材料对模型进行微调，以提高其在该子领域的绩效。此外，为了更好地了解用户需求，可以引入多模态输入[64]，例如允许用户通过语音或图像提供法律问题。同样，模型可以根据用户需求和场景提供多模态输出，例如语音、文本、图表等。
	- ii) **法律专家和从业人员的参与**。邀请法律专家、法官、检察官、律师参与司法人工智能的开发和评估过程。他们可以提供宝贵的法律知识和实践经验，帮助指导人工智能系统的设计和培训，确保遵守法律法规和司法实践。此外，法律专家可以评估和完善 LLM 的结果[137]，对其进行微调以提高法律咨询中模型的准确性和可靠性。
	- iii）**用户反馈和持续优化**：在法律LLM的训练过程中，可以采用人类反馈强化学习（RLHF）机器学习方法[80]。
		- 首先，为用户提供反馈机制[90]，鼓励他们积极参与合法LLM的使用，并收集用户反馈。
		- 根据包含用户反馈的注释数据，训练奖励模型（RM）对大语言模型生成的内容进行排名。
		- 最后，通过深度学习更新LLM的参数，使合法的LLM更加符合用户的实际需求。该方法减少了传统强化学习中需要大量试错的问题，并根据用户需求对模型进行优化和调整。

### 6.4.司法实践

- **完善问责机制，防止政治干预**：建立健全问责机制有利于规范人工智能在司法领域的使用，防止法律硕士造成的法律错误[28]。例如，司法错误的责任会阻止法官完全将决策权委托给 LLM ，而是促使他们仔细考虑 LLM 提供的决策建议。此外，我们应该警惕人工智能在司法领域的应用受到政治干预。例如，为推动人工智能在司法领域的应用，各级法院可以收到与人工智能技术运用相关的绩效考核指标。在追求满足这些指标的过程中，法院可能会无意中忽视人工智能的局限性，从而导致司法错误。
- **培养复合型人才**： LLM 出现“算法偏差”、“算法黑箱”等问题的一个重要原因是缺乏法律与技术相结合的复合型人才。鼓励培养兼具法律知识和技术知识的人才[140]。这将使我们能够解决难以转化为算法程序的法律概念的问题。此外，具有法律经验的跨学科人才将能够识别大型数据集中的歧视性元素并消除它们。这也保证了合法LLM算法的安全性，大大降低了“算法黑匣子”发生的概率。
- **协作与分享经验**：人工智能技术在国际上发展迅速。对推理能力的研究可以追溯到20世纪70年代的Mycin系统，随后IBM的Watson模型的建立、LLM的研究以及OpenAI的ChatGPT的发布。在AI领域有着丰富的经验。与国外研究机构、企业、专家合作，分享经验和技术成果。国际合作可以促进各国在人工智能司法领域的交流与合作，共同解决技术和伦理问题。它还可以避免重复工作和错误。



# 创新点：

第一篇 LLM 在法律行业的综述文章，较为完整的阐述了该领域的当前发展和面对的问题

# 启发与思考：

1. 法律LLM难以将某些模糊的法律概念转换为编程符号的问题，参考文献 105
2. 为了解决长文本建模的挑战，我们可以采用==外部召回方法、模型优化[59]和注意力机制的优化==
3. 在 LLM 底层算法层面处理司法数据的过程中，可以引入算法来防止有偏见的因素。例如，可以在原始数据中添加随机噪声，并且可以应用基于差分隐私的算法来保护数据[139]
4. Solaiman [124] 提出了一个使用==以价值为目标的数据集==使语言模型适应社会的过程 (PALMS) [124]。该方法旨在==确保模型公平并且不会歧视某些群体==。
5. 使用法律LLM与传统司法方法处理特定案件的时间、资源和人力消耗。（使用GIME评估新的法律LLM）

# 不足及可改进的点：

写作中一些说法过于冗余，读起来很费劲。可以使用更多图表，简化描述。




> [!warning] 注意
> 只用作回顾内容，不要边看边做笔记！会分散注意力！！
